{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "### By: Kolton Cox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks in Machine Learning \n",
    "Neural networks is a branch of machine-learning that is inspired by the neurons in the brain. Mark Stadtmueller, VP of product strategy at AI platform provider Lucd said, “A brain neuron receives an input and based on that input, fires off an output that is used by another neuron. The neural network simulates this behavior in learning about collected data and then predicting outcomes,”.\n",
    "\n",
    "Two main characteristics of a neural network:\n",
    "\n",
    "- Architecture\n",
    "- Learning\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "- It tells about the connection type: whether it is feedforward, recurrent, multi-layered, convolutional, or single layered. It also tells about the number of layers and the number of neurons in every layer.\n",
    "\n",
    "#### Learning\n",
    "\n",
    "- It tells about the method in which the neural network is trained. A common way to train a neural network is to use gradient descent and backpropagation.\n",
    "\n",
    "#### Building Steps for the Neural Network\n",
    "For our purposes, we will build a multilayered perceptron with $L$ layers.\n",
    "\n",
    "For $l = 2, \\dots, L$, each layer $l$ in our network will have two phases, the preactivation phase$$z^l = W^la^{l-1} + b^l,$$and postactivation phase$$a^l = \\sigma(z^l).$$The preactivation phase consists of a weighted linear combination of postactivation values in the previous layer. The postactivation values consists of passing the preactivation value through an activation function elementwise. Note $a^1 = x$, where $x$ is the current input data into our network. For our activation function, we will use the sigmoid function:\n",
    "\n",
    "Sigmoid Function$$\n",
    "\\sigma(s) = \\frac{1}{1+e^{-s}}.\n",
    "$$\n",
    "For our cost function, we will use the Mean Sqaure Error cost:$$\n",
    "C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n||a^i - y^i||^2.\n",
    "$$\n",
    "\n",
    "## MNIST Data Set\n",
    "- The MNIST data set consists of 70,000 images of hand written digits, 60,000 of which are typically used as labeled training examples, where the other 10,000 are used for testing your learing model on. The following picture represents a sample of some of the images. \n",
    "- To access this data set, as well as view the data s an image, we need the following packages:\n",
    "  + MNIST [documentation](http://yann.lecun.com/exdb/mnist/)\n",
    "  + MLDatasets [documentation](https://juliaml.github.io/MLDatasets.jl/latest/)\n",
    "  + Images [documentation](https://github.com/JuliaImages/juliaimages.github.io)\n",
    "  + TestImages [documentation](https://testimages.juliaimages.org/)\n",
    "  + ImageMagicIO [documentation](https://juliapackages.com/p/imagemagick)\n",
    "  \n",
    "![](https://raw.githubusercontent.com/RandyRDavila/Teaching/6a86485c40b053f0feca82e32ae1fcaa1481ea26/UHD_DATA/DATA_4319/Supervised_Learning/Neural_Network/MnistExamples.png)\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using MLDatasets\n",
    "using Images\n",
    "using TestImages\n",
    "using Plots\n",
    "\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x, test_y = MNIST.testdata();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "The data structures train_x and test_x are stored as 3 dimensional tensors. \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 60000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Each image in the image is comprised of a 28 x 28 grey scaled grid of pixel values. These values are floating point numbers in the interval(0,1), where darker pixels will have values closer to 1 and lighter pixels will have values closer to 0. the following image represents one such example.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{N0f8,2} with eltype Normed{UInt8,8}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.216  0.533  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.675  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.071  0.886  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.671  0.992  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.118     0.859  0.992  0.831  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.141     0.992  0.992  0.529  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.369  …  0.992  0.992  0.518  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.604     0.992  0.957  0.063  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.012  0.667     0.992  0.522  0.0    0.0  0.0  0.0\n",
       " ⋮                        ⋮             ⋱                       ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.494  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.533  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.686  0.882     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.102  0.675     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.651  0.992  …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0    0.949     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.969  0.765     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.498  0.251     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first image in our train data is labeled 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIKSURBVGje7dpPiI1RGMfxzyAL8qfZmFISi1EiFigpSZJiMbGhbLBDVjZ2FqSwQBazUhayxYryd6FuTf5syN6fHYM0yGDxvJPr3tu9c2eKc0/nW29v5z3ve3/93qdz3uc551IoFAqFQqHQ+/R1+8BMLKhrH8EcDOIwzmEvvuIMTjY8P+NfO8xfcFanG5ZgNjZiExZid4v7XuMihvAZz/EwBYf5C7Ydh2tx19/jrhU/cQBfqvZbfMCrFBzmL9g2hv2oYVmLvhpGsQXfdY7zf3OYv2DbufQ9jmMnnoq5Ep5hmxh3K3EsZYf5C04qp5kvvnHDOIj9uNYrDvMX7JjTwKfq/LE6H8J18R1M3mH+gl3VFnNxC5uxA3d6wWH+gl3Xh8vxROQz9zGCy/iVqsP8BbuOIVEDXsG8qn0CV/EuRYf5C04phrAK57G1ag/jFN6k5jB/wSnHkFiz2SXGZB/uiZojKYf5C04rhhN8EwnuD2zHg5Qc5i84qdqiFauxB+vqfuQFHqXmMH/BrmM4iKMirxmouz4ucppONWP+rzTduXQA+8T+0tKGvhGRz9xM0WH+gh1juEisiV7Cioa+Gs7ihsmv2eT/StOJYb+oF9Zo3rd4LOqK2xhL3WH+gk0x3CD2KtZjcUPfGC7gtD97hck7zF+wKacZqo4JXoo10nHxP4vRXnOYv2ChUCgUps9vDE1MYMzifHwAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"The first image in our train data is labeled \", train_y[1])\n",
    "colorview(Gray, train_x[:, :, 1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "Each training image is a 28x28 matrix. In order to pass these images into our neural network we will need to flatten the training instances (matrices) into a set of vectors. This can be done with the following code.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784-element Array{N0f8,1} with eltype Normed{UInt8,8}:\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " ⋮\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape(train_x[:, :, 1], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i = 1:60000\n",
    "    push!(X, reshape(train_x[:, :, i], 784))\n",
    "    y = zeros(10)\n",
    "    y[train_y[i] + 1] = 1.0\n",
    "    push!(Y, y)\n",
    "end\n",
    "train_data = [x for x in zip(X, Y)]\n",
    "\n",
    "# Test Data\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i = 1:10000\n",
    "    push!(X, reshape(test_x[:, :, i], 784))\n",
    "    y = zeros(10)\n",
    "    y[test_y[i] + 1] = 1.0\n",
    "    push!(Y, y)\n",
    "end\n",
    "test_data = [x for x in zip(X, Y)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_network (generic function with 1 method)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the activation function and its derivative\n",
    "σ(x) = 1.0/(1.0 + exp(-x))\n",
    "\n",
    "dσ(x) = σ(x)*(1-σ(x))\n",
    "\n",
    "# Define a neural network type\n",
    "mutable struct neural_network\n",
    "    W\n",
    "    b\n",
    "end\n",
    "\n",
    "\n",
    "function create_network(input_layer_size, hidden_layer_sizes, output_layer_size)\n",
    "    \n",
    "    W = [[0.0], randn(hidden_layer_sizes[1], input_layer_size)]\n",
    "    \n",
    "    b = [[0.0], randn(hidden_layer_sizes[1])]\n",
    "    \n",
    "    for i = 2:length(hidden_layer_sizes)\n",
    "        push!(W, randn(hidden_layer_sizes[i], hidden_layer_sizes[i-1]))\n",
    "        push!(b, randn(hidden_layer_sizes[i]))\n",
    "    end\n",
    "    \n",
    "    push!(W, randn(output_layer_size, hidden_layer_sizes[end]))\n",
    "    push!(b, randn(output_layer_size))\n",
    "    \n",
    "    return neural_network(W, b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network(Array{Float64,N} where N[[0.0], [-0.42157263373253884 0.3403603929875391 … 0.7059593979544831 0.20027866838686909; -0.5511582050303858 -0.6202309730824873 … 1.1173789604463185 0.8469990700742954; … ; -1.2674191289822463 -0.352451532255533 … -0.25369784434266657 0.9237549894255448; 0.5888241528827143 -0.6671474057077613 … -0.010898713052919846 1.3197409851870658], [0.8397164914381363 0.06281299272341709 … 0.20024784159505282 -1.5823814028819243; 0.17787394387725067 1.0472227870363326 … -0.5207907779785867 -0.4746814500619013; … ; 1.416902595526563 0.807407900114016 … -0.6877930032581488 -0.08114396872700133; -0.4189263012382215 -0.22948097477918517 … 0.19925301828344527 0.719441135225275], [-1.398287473240797 2.92465412620271 … -0.9002921970459473 -0.2728782607109108; -0.9302691329535332 0.31258103048954944 … 0.2765191153840039 0.8920706970356788; … ; -0.5061578840948949 1.0795188227173116 … 1.9463871854577042 -0.5814913765779086; 0.5550701595304238 0.8229256331507262 … 0.47068502316862165 0.6513245767627182], [-0.11542378886674298 0.3432611970683968 … 0.11202838985018793 2.12929450328224; 0.38756319437987347 -0.5674811207957597 … -0.46886294721043287 -0.6413501013597337; … ; 0.28051586386528826 2.444388985913406 … -1.1879852829925877 -1.3124925015000621; 0.34676036155636975 -1.179418735155823 … 0.4983095033784801 0.7983980765167081]], [[0.0], [0.10275536721573753, 0.007243036350538597, 0.9441496753644434, -0.020531630096775742, -0.2458616145092062, -1.273446645922761, -0.3276151701928913, -0.6695476941059716, 0.4665268009843088, 1.6718325124683528  …  0.164690876749953, 0.7978162570548456, 0.15033076907162551, -0.04534970479971665, 2.008924749950115, 0.6539005111276739, 0.9204727989025456, 0.4939202422286082, 0.22041934059748014, 2.4725046120429073], [0.7735034120902646, 2.1490270454889084, 0.555544472489522, -0.820121319943974, 0.38309703494700004, -1.546855963644109, -0.6646626672102393, -0.9536179181598912, 0.04578589141313067, 0.4136712711944022  …  -1.62988773454655, 0.04214164184940698, 0.2817405025640712, 0.11741329715631275, -0.403308719563674, -0.6133131167655759, -2.03613847639237, -1.557068522364547, 0.07496416402747061, 1.5256148597428278], [-1.6596112165035948, -0.5770173413904869, -1.0021699812248945, 0.47504031914672357, -0.12443633444359979, 0.24441097660736774, 0.190849482823547, -0.5115114671807409, -0.8745433122799645, 1.0425126930173532  …  0.8930857178250684, -0.09653216645859146, 1.024901910775457, -0.6616610571524115, 0.7747361653533877, 0.5496324788253957, 1.1313106970485296, -0.3328594367159924, -0.2739625314506127, 0.3135342397570814], [1.0481675765375331, 0.2799239744198628, 0.4141904888780534, 0.07149959810088842, 0.46023148470769054, 1.989152542638149, -0.8868274301120529, 0.6134660650109146, 0.4011753329015555, 0.8700932159275431]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = create_network(784, [100, 100, 100], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Array{Float64,N} where N,1}:\n",
       " [0.0]\n",
       " [-0.42157263373253884 0.3403603929875391 … 0.7059593979544831 0.20027866838686909; -0.5511582050303858 -0.6202309730824873 … 1.1173789604463185 0.8469990700742954; … ; -1.2674191289822463 -0.352451532255533 … -0.25369784434266657 0.9237549894255448; 0.5888241528827143 -0.6671474057077613 … -0.010898713052919846 1.3197409851870658]\n",
       " [0.8397164914381363 0.06281299272341709 … 0.20024784159505282 -1.5823814028819243; 0.17787394387725067 1.0472227870363326 … -0.5207907779785867 -0.4746814500619013; … ; 1.416902595526563 0.807407900114016 … -0.6877930032581488 -0.08114396872700133; -0.4189263012382215 -0.22948097477918517 … 0.19925301828344527 0.719441135225275]\n",
       " [-1.398287473240797 2.92465412620271 … -0.9002921970459473 -0.2728782607109108; -0.9302691329535332 0.31258103048954944 … 0.2765191153840039 0.8920706970356788; … ; -0.5061578840948949 1.0795188227173116 … 1.9463871854577042 -0.5814913765779086; 0.5550701595304238 0.8229256331507262 … 0.47068502316862165 0.6513245767627182]\n",
       " [-0.11542378886674298 0.3432611970683968 … 0.11202838985018793 2.12929450328224; 0.38756319437987347 -0.5674811207957597 … -0.46886294721043287 -0.6413501013597337; … ; 0.28051586386528826 2.444388985913406 … -1.1879852829925877 -1.3124925015000621; 0.34676036155636975 -1.179418735155823 … 0.4983095033784801 0.7983980765167081]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wieghts\n",
    "NN.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Array{Float64,1},1}:\n",
       " [0.0]\n",
       " [0.10275536721573753, 0.007243036350538597, 0.9441496753644434, -0.020531630096775742, -0.2458616145092062, -1.273446645922761, -0.3276151701928913, -0.6695476941059716, 0.4665268009843088, 1.6718325124683528  …  0.164690876749953, 0.7978162570548456, 0.15033076907162551, -0.04534970479971665, 2.008924749950115, 0.6539005111276739, 0.9204727989025456, 0.4939202422286082, 0.22041934059748014, 2.4725046120429073]\n",
       " [0.7735034120902646, 2.1490270454889084, 0.555544472489522, -0.820121319943974, 0.38309703494700004, -1.546855963644109, -0.6646626672102393, -0.9536179181598912, 0.04578589141313067, 0.4136712711944022  …  -1.62988773454655, 0.04214164184940698, 0.2817405025640712, 0.11741329715631275, -0.403308719563674, -0.6133131167655759, -2.03613847639237, -1.557068522364547, 0.07496416402747061, 1.5256148597428278]\n",
       " [-1.6596112165035948, -0.5770173413904869, -1.0021699812248945, 0.47504031914672357, -0.12443633444359979, 0.24441097660736774, 0.190849482823547, -0.5115114671807409, -0.8745433122799645, 1.0425126930173532  …  0.8930857178250684, -0.09653216645859146, 1.024901910775457, -0.6616610571524115, 0.7747361653533877, 0.5496324788253957, 1.1313106970485296, -0.3328594367159924, -0.2739625314506127, 0.3135342397570814]\n",
       " [1.0481675765375331, 0.2799239744198628, 0.4141904888780534, 0.07149959810088842, 0.46023148470769054, 1.989152542638149, -0.8868274301120529, 0.6134660650109146, 0.4011753329015555, 0.8700932159275431]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Biases\n",
    "NN.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "\n",
      "(100, 784)\n",
      "\n",
      "(100, 100)\n",
      "\n",
      "(100, 100)\n",
      "\n",
      "(10, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the dimensions of the network\n",
    "for w in NN.W\n",
    "    println(size(w))\n",
    "    println(\"\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success_percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forward_pass(network, training_instance)\n",
    "    Z = [[0.0]]\n",
    "    A = [training_instance[1]]\n",
    "    \n",
    "    for i = 2:length(network.W)\n",
    "        push!(Z, network.W[i]*A[i-1] + network.b[i])\n",
    "        push!(A, σ.(Z[i]))\n",
    "    end\n",
    "    \n",
    "    return Z, A\n",
    "end\n",
    "\n",
    "function predict(network, training_instance)\n",
    "    Z, A = forward_pass(network, training_instance)\n",
    "    return argmax(A[end]) - 1\n",
    "end\n",
    "\n",
    "function success_percentage(network, data_set)\n",
    "    return string(\"The percentage of correctly classified images is: \", sum([predict(network, x) == argmax(x[2]) - 1 ? 1 : 0 for x in data_set])/length(data_set)*100.,\" %\")\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The percentage of correctly classified images is: 11.07 %\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_percentage(NN, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "function error_deltas(network, training_instance)\n",
    "    Z, A = forward_pass(network, training_instance)\n",
    "    L = size(network.W)[1]\n",
    "    δ = [(A[end] - training_instance[2]).*dσ.(Z[end])]\n",
    "    for i = L-1:-1:2\n",
    "        pushfirst!(δ, (network.W[i+1]'*δ[1]).*dσ.(Z[i]))\n",
    "    end\n",
    "    pushfirst!(δ, [0.0])\n",
    "    return A, δ\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test, δ_test = error_deltas(NN, train_data[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       "  0.1415273836073831\n",
       "  0.011695219604108104\n",
       "  0.00024630372747281226\n",
       "  1.1735711564211111e-5\n",
       "  1.2522332755040525e-6\n",
       " -4.2823753350761954e-5\n",
       "  0.05883450595563337\n",
       "  0.0007228692404233542\n",
       "  0.0\n",
       "  0.011595527162725088"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δ_test[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_random_mini_batch(mini_batch_size, data_set)\n",
    "    k = rand(1:size(data_set)[1] - mini_batch_size)\n",
    "    return data_set[k:k + mini_batch_size]\n",
    "end\n",
    "\n",
    "function mini_batch_update!(network::neural_network, mini_batch_size::Int64, data_set, α::Float64)\n",
    "    \n",
    "    mini_batch = make_random_mini_batch(mini_batch_size, data_set)\n",
    "    L = size(network.W)[1]\n",
    "    \n",
    "    A, δ = error_deltas(network, mini_batch[1])\n",
    "    A_batch = []\n",
    "    δ_batch = []\n",
    "    push!(A_batch, A)\n",
    "    push!(δ_batch, δ)\n",
    "    \n",
    "    for i = 2:mini_batch_size\n",
    "        A, δ = error_deltas(network, mini_batch[i])\n",
    "        push!(A_batch, A)\n",
    "        push!(δ_batch, δ)\n",
    "    end\n",
    "    \n",
    "    for l = L:-1:2\n",
    "        network.W[l] -= (α/mini_batch_size)*sum([δ_batch[i][l]*A_batch[i][l-1]' for i = 1:mini_batch_size])\n",
    "        network.b[l] -= (α/mini_batch_size)*sum([δ_batch[i][l] for i = 1:mini_batch_size])\n",
    "    end\n",
    "end;   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 5000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 10.71 %\n",
      "\n",
      "Epochs 10000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 79.10000000000001 %\n",
      "\n",
      "Epochs 15000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 88.12 %\n",
      "\n",
      "Epochs 20000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 89.25 %\n",
      "\n",
      "Epochs 25000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 89.9 %\n",
      "\n",
      "Epochs 30000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 91.03 %\n",
      "\n",
      "Epochs 35000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 90.88000000000001 %\n",
      "\n",
      "Epochs 40000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 92.28 %\n",
      "\n",
      "Epochs 45000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 93.03 %\n",
      "\n",
      "Epochs 50000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 92.58999999999999 %\n",
      "\n",
      "Epochs 55000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 92.47 %\n",
      "\n",
      "Epochs 60000\n",
      "The percentage of correct classified images is:The percentage of correctly classified images is: 93.69 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i = 1:60000\n",
    "    mini_batch_update!(NN, 2, train_data, 0.4)\n",
    "    if i % 5000 == 0\n",
    "        println(\"Epochs \",i)\n",
    "        println(\"The percentage of correct classified images is:\",success_percentage(NN, test_data),\"\\n\")       \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The percentage of correctly classified images is: 93.69 %\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_percentage(NN, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts:\n",
    "\n",
    "- What we can see above is that the program is working nicely. \n",
    "- We can see that increasing batch size as well as decreasing learning rate has potential to increases accuracy in prediction of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_test_example (generic function with 1 method)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function show_test_img(i)\n",
    "    colorview(Gray, test_x[:,:,i]')\n",
    "end\n",
    "\n",
    "function show_test_example(network::neural_network, i::Int64, testing_data)\n",
    "    println(\"Predicted label: \", predict(network, testing_data[i]))\n",
    "    println(\"Actual label: \", argmax(testing_data[i][2])-1)\n",
    "    show_test_img(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 5\n",
      "Actual label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAGaSURBVGje7di/S1VxGMfxl9qPSRoa2gOHiiSJgiCIhgxC8B/IycDFLXAQahNpbymoubkipIxaksQhaEj7gS7hUENUNAQSDefcJYjOybDveXjeyznc8+W874cP93vPc0iSJEmSpK/N4n78wD5cwDkM4hNO4gimceMP99hR4gsbd3gUt7CJIRzCC3zGezzF7RITxhfuarrwLVYwhQ8YV/X2tfSE8YWt9lJYxgkcw8suJExhCssXNt5LYQC7u5YwvrBVhwdwuGsJ4wtbdfgNaxjuUsL4wlYdTtpef/8lYXxhqw6f4xmOq2bFa7iH7yUnjC9sPVvAQYxgHg9xRfWupsiE8YV/1WGP/Zirv/Vd3C8xYXzhtjrsMYGbGMPj0hLGF7b6P/wdb7AXl2WHXe2wx+sSE8YX/pMOr9bH9RITxhc26nAIM6pZ4t0v12ZxvuSE8YWNnmkWMIrTWKo/G8R1XKxv8gpn8bG0hPGFjX6Hd+qFT7CIDVzCHqzW5yvYKjFhfGHj2aIfp1TzwxlVd4/wAF9KThhfmCRJkiQJPwEBmTaINLAQXgAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = rand([x for x = 1:10000])\n",
    "show_test_example(NN, i, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
